# -*- coding: utf-8 -*-
"""COVID19_Divyarth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ikkt53AyMRtsVr5CGyOoErr618YJwpdE
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import math


from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
# Keep same random seed to get reproducible results || When ran on GPU results not reproducible
np.random.seed(7)

data = pd.read_csv('/content/drive/My Drive/COVID19/COVID19.csv')

data['Country'] = data['Country/Region']
ser=pd.Series(data=data[data['Province/State'].notnull()]['Country'].values+" "+data[data['Province/State'].notnull()]['Province/State'].values,index=data[data['Province/State'].notnull()]['Country'].index)
index= data[data['Province/State'].notnull()]['Country'].index

# Each Province Being treates independantly

for i in index:
  data.at[i,"Country"]=ser[i]
data=data.set_index("Country")
data=data.drop(['Province/State', 'Country/Region', 'Lat', 'Long'],axis=1).T

for i in range (len(data.index)):
  if data.index[i] == "India":
    break
print(i)

data["India"]



data['pred']=data.India.shift(-1)
data=data.dropna()

values=data.values
values=values.astype('float32')
#scaler=MinMaxScaler(feature_range=(0,1))
#scaled=scaler.fit_transform(values)
#scaled=pd.DataFrame(scaled)
# max_d = max(data.India)
# scaled = data/max_d

# data["World"]=data.sum(axis=1)

# train and test have the pred at -1

def scale(train, test):
	scaler = MinMaxScaler(feature_range=(-1, 1))
	scaler = scaler.fit(train)
	train = train.reshape(train.shape[0], train.shape[1])
	train_scaled = scaler.transform(train)
	test = test.reshape(test.shape[0], test.shape[1])
	test_scaled = scaler.transform(test)
	return scaler, train_scaled, test_scaled
 
# inverse scaling for a forecasted value
def invert_scale(scaler, X, yhat):
	new_row = [x for x in X] + [yhat]
	array = np.array(new_row)
	array = array.reshape(1, len(array))
	inverted = scaler.inverse_transform(array)
	return inverted[0, -1]



# data_scaled = scaled.to_numpy()
dataset = values[:,[131,-1]]

n=int(len(dataset)*0.67)
train,test=dataset[:n,:],dataset[n:,:]
scaler,train_scaled,test_scaled=scale(train,test)
trainX = train_scaled[:,0:-1]
trainY = train_scaled[:,-1]
#testX = dataX[int(0.67*len(dataX)):,:]
testX = test_scaled[:,0:-1]
testY = test_scaled[:,-1]
trainX = np.reshape(trainX, (trainX.shape[0], 1, 1))
testX = np.reshape(testX, (testX.shape[0], 1, 1))
# get the X_test from test and use this yhat to transform using the scaler obtained above and invert_scale function

look_back = 1
import tensorflow as tf


from tensorflow.keras.layers import Input, Dense, LSTM
from tensorflow.keras.models import Sequential

def get_model():
  model = Sequential()
  #model.add(LSTM(4, input_shape=(1, 256)))
  model.add(LSTM(4, input_shape=(1, 1)))
  model.add(Dense(1))
  return model
model = get_model()


model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

X=np.concatenate((trainX,testX),axis=0)
yhat=model.predict(X)
data_pred=np.concatenate(((X.reshape(dataset[:,0:-1].shape)),yhat),axis=1)
yf=scaler.inverse_transform(data_pred)[:,-1]
# pred= scaler.inverse_transform(np.concatenate((dataset[:,:-1],yhat),axis=1))

# Plotting cases for a country
y=dataset[:,-1]
# x=y.index.values.tolist() 

fig, ax = plt.subplots()
ax.plot(y)
ax.plot(yf)

ax.set(xlabel='Date', ylabel='Numbers Infected',title='Infected in India')

# ax.xaxis.set_ticks(np.asarray(range(0,len(y),7)))
# ax.set_xticklabels(x, rotation=45)

# ax.grid()
fig.show()

trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
# invert predictions
trainPredict = trainPredict*max_d
trainY = trainY*max_d
testPredict = testPredict*max_d
testY = testY*max_d
# calculate root mean squared error
trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

trainPredictPlot = []
trainPredictPlot[look_back:len(trainPredict)+look_back] = trainPredict[:,0]
testPredictPlot = np.empty((len(data)+1))
testPredictPlot[:] = np.nan
testPredictPlot[len(trainPredictPlot)+look_back:] = testPredict[:,0]
plt.plot(data.India)
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()







trainY

data["pred"]

def ts(new_data,look_back=3,pred_col=1):
  t=new_data.copy()
  t["id"]=range(1,len(t)+1)
  t=t.iloc[:-look_back,:]
  t.set_index("id",inplace=True)
  pred_value=new_data.copy()
  pred_value=pred_value.iloc[look_back:,pred_col]
  pred_value.columns=["Pred"]
  pred_value=pd.DataFrame(pred_value)
  pred_value["id"]=range(1,1+len(pred_value))
  pred_value.set_index("id",inplace=True)
  final_df=pd.concat([t,pred_value],axis=1)
  return final_df

arr_df=ts(scaled,3,0)
arr_df.fillna(0,inplace=True)
arr_df.tail()





# split into train and test sets
dataset=dataset.values.reshape(len(dataset),1)
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
print(len(train), len(test))

# convert an array of values into a dataset matrix; look_back is the window width
def create_dataset(dataset, look_back=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-look_back-1):
		a = dataset[i:(i+look_back), 0]
		dataX.append(a)
		dataY.append(dataset[i + look_back, 0])
	return np.array(dataX), np.array(dataY)





data = scaled.to_numpy()

dataX = data[:,:-1]
dataY = data[:,-1]

dataY

dataX = data[:,:-1]
dataY = data[:,-1]

trainX = dataX[:int(0.67*len(dataX)),:]
trainY = dataY[:int(0.67*len(dataY))]
testX = dataX[int(0.67*len(dataX)):,:]
testY = dataY[int(0.67*len(dataY)):]

look_back = 1
#trainX, trainY = create_dataset(train, look_back)
#testX, testY = create_dataset(test, look_back)
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
#trainY = np.reshape(trainY, (trainY.shape[0], 1, trainX.shape[1]))

trainX.shape

import tensorflow as tf


from tensorflow.keras.layers import Input, Dense, LSTM
from tensorflow.keras.models import Sequential

def get_model():
  model = Sequential()
  model.add(LSTM(4, input_shape=(1, 256)))
  model.add(Dense(1))
  return model
model = get_model()

pip install -U keras

model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
# invert predictions
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform(trainY)
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform(testY)
# calculate root mean squared error
trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

#trainPredictPlot = np.empty_like(data)
#trainPredictPlot[:] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back,0] = trainPredict[:,0]
# shift test predictions for plotting
testPredictPlot = np.empty_like(data)
testPredictPlot[:] = np.nan
testPredictPlot[0:24,0] = testPredict[:,0]
# plot baseline and predictions
plt.plot(scaler.inverse_transform(scaled))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()



trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
# invert predictions
trainPredict = trainPredict
trainY = trainY
testPredict = testPredict
testY = testY
# calculate root mean squared error
trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))
trainY.shape
data
scaled.head(4)
